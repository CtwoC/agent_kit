"""
èŠå¤©å¤„ç†æ¨¡å—
è´Ÿè´£AIå¯¹è¯ç”Ÿæˆã€æµå¼å†…å®¹å¤„ç†å’ŒRedisä¸­è½¬å­˜å‚¨
"""

import asyncio
import json
import uuid
from typing import Dict, Any, Optional, AsyncGenerator
from datetime import datetime

from utils.logger import get_logger
from utils.status_codes import ChatStatus, create_status_info
from models.api_models import CustomerProfile, CustomerMemory
from storage.redis_client import get_redis_client
from config.settings import get_settings

logger = get_logger(__name__)

class ChatProcessor:
    """èŠå¤©å¤„ç†æ ¸å¿ƒ"""
    
    def __init__(self):
        self.settings = get_settings()
        
    async def process(self, enhanced_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†AIå¯¹è¯ç”Ÿæˆ
        
        Args:
            enhanced_data: åŒ…å«Profileæ•°æ®çš„å¢å¼ºè¯·æ±‚å­—å…¸
            
        Returns:
            Dict[str, Any]: åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
        """
        uid = enhanced_data.get("uid")
        message = enhanced_data.get("message")
        session_id = enhanced_data.get("session_id") or str(uuid.uuid4())
        
        logger.info(f"ğŸ’¬ å¼€å§‹å¤„ç†å®¢æˆ·å¯¹è¯: {uid}")
        
        # æ›´æ–°çŠ¶æ€
        status_info = create_status_info(
            ChatStatus.PROCESSING,
            message=f"AIæ­£åœ¨ä¸ºå®¢æˆ· {uid} ç”Ÿæˆå›å¤",
            progress=0.2
        )
        
        try:
            # è·å–Rediså®¢æˆ·ç«¯ç”¨äºæµå¼å­˜å‚¨
            redis_client = await get_redis_client()
            
            # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
            context = await self._build_context(enhanced_data)
            
            # åˆå§‹åŒ–æµå¼å­˜å‚¨
            stream_key = f"stream:{uid}:{session_id}"
            await self._init_stream_storage(redis_client, stream_key, enhanced_data)
            
            # æ›´æ–°çŠ¶æ€ä¸ºæµå¼è¾“å‡º
            status_info.status = ChatStatus.STREAMING
            status_info.message = "å¼€å§‹æµå¼ç”Ÿæˆå›å¤"
            status_info.progress = 0.3
            
            # æµå¼ç”Ÿæˆå¯¹è¯
            response_content = ""
            tokens_used = 0
            
            async for chunk_data in self._generate_stream_response(context, enhanced_data):
                # å†™å…¥Redisæµå¼å­˜å‚¨
                await self._write_stream_chunk(redis_client, stream_key, chunk_data)
                
                # ç´¯ç§¯å†…å®¹
                if chunk_data.get("type") == "content":
                    response_content += chunk_data.get("chunk", "")
                    
                # æ›´æ–°è¿›åº¦
                if chunk_data.get("type") == "progress":
                    status_info.progress = min(0.9, 0.3 + chunk_data.get("progress", 0) * 0.6)
                
                # è®°å½•tokenä½¿ç”¨æƒ…å†µ
                if chunk_data.get("type") == "usage":
                    tokens_used = chunk_data.get("total_tokens", 0)
            
            # å®Œæˆå¤„ç†
            completion_data = {
                **enhanced_data,
                "response_content": response_content,
                "tokens_used": tokens_used,
                "session_id": session_id,
                "stream_key": stream_key,
                "processing_timestamp": datetime.now(),
                "status": create_status_info(
                    ChatStatus.COMPLETED,
                    message="AIå¯¹è¯ç”Ÿæˆå®Œæˆ",
                    progress=1.0
                )
            }
            
            # æ ‡è®°æµå¼å­˜å‚¨å®Œæˆ
            await self._complete_stream_storage(redis_client, stream_key, completion_data)
            
            logger.info(f"âœ… å®¢æˆ·å¯¹è¯å¤„ç†å®Œæˆ: {uid}, tokens: {tokens_used}")
            
            return completion_data
            
        except Exception as e:
            logger.error(f"âŒ å®¢æˆ·å¯¹è¯å¤„ç†å¤±è´¥ {uid}: {str(e)}")
            
            # åˆ›å»ºé”™è¯¯å“åº”
            error_data = {
                **enhanced_data,
                "response_content": f"å¾ˆæŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é—®é¢˜: {str(e)}",
                "tokens_used": 0,
                "session_id": session_id,
                "processing_error": str(e),
                "processing_timestamp": datetime.now(),
                "status": create_status_info(
                    ChatStatus.ERROR,
                    message=f"å¯¹è¯ç”Ÿæˆå¤±è´¥: {str(e)}",
                    error_details=str(e)
                )
            }
            
            return error_data
    
    async def _build_context(self, enhanced_data: Dict[str, Any]) -> str:
        """æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡"""
        try:
            profile: CustomerProfile = enhanced_data.get("customer_profile")
            memory: CustomerMemory = enhanced_data.get("customer_memory") 
            preferences = enhanced_data.get("customer_preferences", {})
            message = enhanced_data.get("message")
            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt(profile, preferences)
            
            # æ„å»ºå¯¹è¯å†å²
            conversation_history = self._build_conversation_history(memory)
            
            # ç»„åˆå®Œæ•´ä¸Šä¸‹æ–‡
            context_parts = [
                f"ç³»ç»Ÿæç¤ºè¯:\n{system_prompt}",
                f"å¯¹è¯å†å²:\n{conversation_history}" if conversation_history else "",
                f"å®¢æˆ·å½“å‰æ¶ˆæ¯:\n{message}"
            ]
            
            context = "\n\n".join(part for part in context_parts if part)
            
            logger.debug(f"æ„å»ºä¸Šä¸‹æ–‡å®Œæˆï¼Œé•¿åº¦: {len(context)} å­—ç¬¦")
            return context
            
        except Exception as e:
            logger.warning(f"ä¸Šä¸‹æ–‡æ„å»ºå¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ¨¡å¼: {str(e)}")
            return f"ç”¨æˆ·æ¶ˆæ¯: {enhanced_data.get('message', '')}"
    
    def _build_system_prompt(self, profile: CustomerProfile, preferences: Dict[str, Any]) -> str:
        """æ„å»ºä¸ªæ€§åŒ–ç³»ç»Ÿæç¤ºè¯"""
        base_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå®¢æœåŠ©æ‰‹ï¼Œèƒ½å¤Ÿä¸ºå®¢æˆ·æä¾›ä¼˜è´¨çš„æœåŠ¡å’Œæ”¯æŒã€‚"""
        
        # æ ¹æ®å®¢æˆ·ç­‰çº§è°ƒæ•´
        if profile.service_level == "premium":
            base_prompt += "\nä½ æ­£åœ¨ä¸ºVIPå®¢æˆ·æä¾›æœåŠ¡ï¼Œè¯·æ ¼å¤–ç”¨å¿ƒå’Œä¸“ä¸šã€‚"
        elif profile.service_level == "enterprise":
            base_prompt += "\nä½ æ­£åœ¨ä¸ºä¼ä¸šå®¢æˆ·æä¾›æœåŠ¡ï¼Œè¯·ä¿æŒå•†åŠ¡ä¸“ä¸šçš„æ²Ÿé€šé£æ ¼ã€‚"
        
        # æ ¹æ®å†å²æ»¡æ„åº¦è°ƒæ•´
        if profile.satisfaction_score and profile.satisfaction_score < 3.0:
            base_prompt += "\nè¿™ä½å®¢æˆ·ä¹‹å‰çš„æ»¡æ„åº¦è¾ƒä½ï¼Œè¯·ç‰¹åˆ«è€å¿ƒå’Œç»†è‡´åœ°è§£ç­”é—®é¢˜ã€‚"
        
        # æ ¹æ®åå¥½è°ƒæ•´
        if preferences.get("communication_style") == "formal":
            base_prompt += "\nè¯·ä½¿ç”¨æ­£å¼çš„æ²Ÿé€šé£æ ¼ã€‚"
        elif preferences.get("communication_style") == "casual":
            base_prompt += "\nè¯·ä½¿ç”¨è½»æ¾å‹å¥½çš„æ²Ÿé€šé£æ ¼ã€‚"
        
        if preferences.get("language") == "en":
            base_prompt += "\nPlease respond in English."
        else:
            base_prompt += "\nè¯·ç”¨ä¸­æ–‡å›å¤ã€‚"
        
        return base_prompt
    
    def _build_conversation_history(self, memory: CustomerMemory) -> str:
        """æ„å»ºå¯¹è¯å†å²"""
        if not memory.short_term:
            return ""
        
        history_parts = []
        
        # æ·»åŠ é•¿æœŸè®°å¿†æ‘˜è¦
        if memory.long_term_summary:
            history_parts.append(f"å†å²å¯¹è¯æ‘˜è¦: {memory.long_term_summary}")
        
        # æ·»åŠ æœ€è¿‘å¯¹è¯
        for conv in memory.short_term[-5:]:  # åªå–æœ€è¿‘5æ¡
            history_parts.append(f"å®¢æˆ·: {conv.customer_message}")
            history_parts.append(f"AI: {conv.agent_message}")
        
        return "\n".join(history_parts)
    
    async def _init_stream_storage(self, redis_client, stream_key: str, enhanced_data: Dict[str, Any]):
        """åˆå§‹åŒ–æµå¼å­˜å‚¨"""
        try:
            init_data = {
                "uid": enhanced_data.get("uid"),
                "session_id": enhanced_data.get("session_id"),
                "start_time": datetime.now().isoformat(),
                "status": "streaming",
                "chunks": []
            }
            
            await redis_client.hset(stream_key, "metadata", json.dumps(init_data))
            await redis_client.expire(stream_key, self.settings.redis.stream_ttl)
            
        except Exception as e:
            logger.warning(f"æµå¼å­˜å‚¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    async def _write_stream_chunk(self, redis_client, stream_key: str, chunk_data: Dict[str, Any]):
        """å†™å…¥æµå¼æ•°æ®å—"""
        try:
            chunk_with_timestamp = {
                **chunk_data,
                "timestamp": datetime.now().isoformat()
            }
            
            await redis_client.lpush(
                f"{stream_key}:chunks", 
                json.dumps(chunk_with_timestamp, ensure_ascii=False)
            )
            
            # é™åˆ¶chunksæ•°é‡ï¼Œé¿å…å†…å­˜è¿‡åº¦ä½¿ç”¨
            await redis_client.ltrim(f"{stream_key}:chunks", 0, 1000)
            
        except Exception as e:
            logger.warning(f"æµå¼æ•°æ®å†™å…¥å¤±è´¥: {str(e)}")
    
    async def _complete_stream_storage(self, redis_client, stream_key: str, completion_data: Dict[str, Any]):
        """å®Œæˆæµå¼å­˜å‚¨"""
        try:
            completion_info = {
                "status": "completed",
                "end_time": datetime.now().isoformat(),
                "total_tokens": completion_data.get("tokens_used", 0),
                "response_length": len(completion_data.get("response_content", ""))
            }
            
            await redis_client.hset(stream_key, "completion", json.dumps(completion_info))
            
        except Exception as e:
            logger.warning(f"æµå¼å­˜å‚¨å®Œæˆæ ‡è®°å¤±è´¥: {str(e)}")
    
    async def _generate_stream_response(self, context: str, enhanced_data: Dict[str, Any]) -> AsyncGenerator[Dict[str, Any], None]:
        """ç”Ÿæˆæµå¼å“åº”ï¼ˆæ¨¡æ‹ŸAIç”Ÿæˆè¿‡ç¨‹ï¼‰"""
        try:
            # æ¨¡æ‹ŸAIå“åº”ç”Ÿæˆ
            # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨OpenAIå®¢æˆ·ç«¯
            
            # å‘é€å¼€å§‹ä¿¡å·
            yield {"type": "start", "message": "å¼€å§‹ç”Ÿæˆå›å¤"}
            
            # æ¨¡æ‹Ÿæµå¼ç”Ÿæˆæ–‡æœ¬
            response_text = f"æ‚¨å¥½ï¼æˆ‘å·²ç»æ”¶åˆ°æ‚¨çš„æ¶ˆæ¯ï¼š{enhanced_data.get('message', '')}ã€‚ä½œä¸ºæ‚¨çš„AIåŠ©æ‰‹ï¼Œæˆ‘å¾ˆä¹æ„ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚"
            
            # åˆ†chunkå‘é€
            chunk_size = self.settings.stream.chunk_size
            for i in range(0, len(response_text), chunk_size):
                chunk = response_text[i:i + chunk_size]
                
                yield {
                    "type": "content",
                    "chunk": chunk,
                    "index": i // chunk_size
                }
                
                # æ¨¡æ‹Ÿç”Ÿæˆå»¶è¿Ÿ
                await asyncio.sleep(self.settings.stream.write_interval)
                
                # å‘é€è¿›åº¦æ›´æ–°
                progress = min(1.0, (i + chunk_size) / len(response_text))
                yield {"type": "progress", "progress": progress}
            
            # å‘é€ä½¿ç”¨æƒ…å†µç»Ÿè®¡
            yield {
                "type": "usage",
                "input_tokens": len(context) // 4,  # ç²—ç•¥ä¼°ç®—
                "output_tokens": len(response_text) // 4,
                "total_tokens": (len(context) + len(response_text)) // 4
            }
            
            # å‘é€å®Œæˆä¿¡å·
            yield {"type": "complete", "message": "å›å¤ç”Ÿæˆå®Œæˆ"}
            
        except Exception as e:
            logger.error(f"æµå¼ç”Ÿæˆå¤±è´¥: {str(e)}")
            yield {"type": "error", "error": str(e)} 