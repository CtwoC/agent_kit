#!/usr/bin/env python3
"""
æµå¼AgentæœåŠ¡ - ä¸»åº”ç”¨å…¥å£
è´Ÿè´£FastAPIè·¯ç”±å’ŒAPIç«¯ç‚¹ç®¡ç†
"""

from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from contextlib import asynccontextmanager
from typing import Optional
import uvicorn

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from load_user import user_manager
from chat_processor import ChatProcessor

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    print("ğŸš€ å¯åŠ¨æ¨¡å—åŒ–æµå¼AgentæœåŠ¡...")
    yield
    print("ğŸ”„ æ­£åœ¨å…³é—­æµå¼AgentæœåŠ¡...")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="æ¨¡å—åŒ–æµå¼AgentæœåŠ¡",
    description="æ”¯æŒç”¨æˆ·çº§å¹¶å‘æ§åˆ¶çš„æ¨¡å—åŒ–æµå¼èŠå¤©Agent",
    version="3.0.0",
    lifespan=lifespan
)

# è¯·æ±‚æ¨¡å‹
class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚æ¨¡å‹"""
    message: str
    uid: str  # ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
    system_prompt: Optional[str] = None  # å¯é€‰çš„è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "æ¨¡å—åŒ–æµå¼AgentæœåŠ¡",
        "version": "3.0.0",
        "features": ["æµå¼èŠå¤©", "å·¥å…·è°ƒç”¨", "ç”¨æˆ·çº§å¹¶å‘æ§åˆ¶", "æ¨¡å—åŒ–è®¾è®¡"],
        "endpoints": ["/chat/stream", "/chat", "/health", "/stats"],
        "modules": ["load_user", "chat_processor", "main"]
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    processing_info = await user_manager.get_processing_users()
    
    return {
        "status": "healthy", 
        "service": "modular_streaming_agent",
        "active_users": processing_info["active_users"],
        "processing_users": processing_info["processing_users"]
    }

@app.post("/chat/stream")
async def stream_chat(request: ChatRequest):
    """
    æµå¼èŠå¤©ç«¯ç‚¹
    
    Args:
        request: åŒ…å«ç”¨æˆ·æ¶ˆæ¯ã€uidå’Œå¯é€‰ç³»ç»Ÿæç¤ºè¯çš„è¯·æ±‚
        
    Returns:
        Server-Sent Eventsæµå¼å“åº”
    """
    uid = request.uid
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²åœ¨å¤„ç†ä¸­
    can_process = await user_manager.check_and_mark_user_processing(uid)
    
    if not can_process:
        error_msg = f"ç”¨æˆ· {uid} æœ‰è¯·æ±‚æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆåå†è¯•"
        print(f"âš ï¸ {error_msg}")
        
        # è¿”å›é”™è¯¯çš„æµå¼å“åº”
        async def error_response():
            import json
            yield f"data: {json.dumps({'type': 'error', 'error': error_msg, 'uid': uid}, ensure_ascii=False)}\n\n"
        
        return StreamingResponse(
            error_response(),
            media_type="text/plain",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*"
            }
        )
    
    # å¤„ç†æµå¼èŠå¤©è¯·æ±‚
    async def stream_with_cleanup():
        """å¸¦æ¸…ç†çš„æµå¼å“åº”ç”Ÿæˆå™¨"""
        try:
            async for chunk in ChatProcessor.process_stream_chat(
                request.message, 
                uid, 
                request.system_prompt
            ):
                yield chunk
        finally:
            # ç¡®ä¿å–æ¶ˆç”¨æˆ·å¤„ç†æ ‡è®°
            await user_manager.unmark_user_processing(uid)
    
    return StreamingResponse(
        stream_with_cleanup(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*"
        }
    )

@app.post("/chat")
async def chat_non_stream(request: ChatRequest):
    """
    éæµå¼èŠå¤©ç«¯ç‚¹
    
    Args:
        request: åŒ…å«ç”¨æˆ·æ¶ˆæ¯ã€uidå’Œå¯é€‰ç³»ç»Ÿæç¤ºè¯çš„è¯·æ±‚
        
    Returns:
        å®Œæ•´çš„å“åº”JSON
    """
    uid = request.uid
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²åœ¨å¤„ç†ä¸­
    can_process = await user_manager.check_and_mark_user_processing(uid)
    
    if not can_process:
        raise HTTPException(
            status_code=429, 
            detail=f"ç”¨æˆ· {uid} æœ‰è¯·æ±‚æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆåå†è¯•"
        )
    
    try:
        # å¤„ç†éæµå¼èŠå¤©è¯·æ±‚
        response = await ChatProcessor.process_chat(
            request.message, 
            uid, 
            request.system_prompt
        )
        return response
        
    except Exception as e:
        print(f"âŒ ç”¨æˆ· {uid} å¤„ç†éæµå¼èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    finally:
        # ç¡®ä¿å–æ¶ˆç”¨æˆ·å¤„ç†æ ‡è®°
        await user_manager.unmark_user_processing(uid)

@app.get("/stats")
async def get_stats():
    """è·å–å½“å‰å¤„ç†çŠ¶æ€ç»Ÿè®¡"""
    processing_info = await user_manager.get_processing_users()
    
    return {
        "service_stats": {
            "active_users": processing_info["active_users"],
            "processing_users": processing_info["processing_users"]
        }
    }

if __name__ == "__main__":
    print("ğŸŒŠ å¯åŠ¨æ¨¡å—åŒ–ç”¨æˆ·çº§å¹¶å‘æ§åˆ¶çš„æµå¼AgentæœåŠ¡...")
    print("ğŸ“– è¯·ç¡®ä¿è®¾ç½®äº†ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
    print("   - OPENAI_API_KEY: OpenAI APIå¯†é’¥")
    print("   - MCP_URL: MCPæœåŠ¡å™¨URL (å¯é€‰)")
    print("   - OPENAI_BASE_URL: OpenAI APIåŸºç¡€URL (å¯é€‰)")
    print()
    print("ğŸ”— æµå¼APIç«¯ç‚¹: POST /chat/stream")
    print("ğŸ”— ä¼ ç»ŸAPIç«¯ç‚¹: POST /chat") 
    print("ğŸ”— å¥åº·æ£€æŸ¥: GET /health")
    print("ğŸ”— ç»Ÿè®¡ä¿¡æ¯: GET /stats")
    print("ğŸ“ æ³¨æ„: ç°åœ¨éœ€è¦åœ¨è¯·æ±‚ä¸­åŒ…å« uid å‚æ•°")
    print()
    print("ğŸ“¦ æ¨¡å—ç»“æ„:")
    print("   - load_user.py: ç”¨æˆ·çŠ¶æ€ç®¡ç†")
    print("   - chat_processor.py: èŠå¤©é€»è¾‘å¤„ç†")
    print("   - main.py: FastAPIåº”ç”¨ä¸»ä½“")
    print()
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8081,
        reload=True,
        log_level="info"
    ) 